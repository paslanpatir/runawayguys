{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manage Session Records\n",
        "\n",
        "This notebook provides utilities to manage session records in DynamoDB/CSV:\n",
        "\n",
        "- **Clear all session data** - Delete all records from session_* tables and files\n",
        "- **Delete a session record** (by session_id) from all related tables\n",
        "- **Update a record** in a selected table by session_id\n",
        "- **List sessions** for viewing\n",
        "- **Reassign Session IDs** - Fix session ID assignments based on (user_id, test_date, boyfriend_name)\n",
        "\n",
        "**Note:** When a record is deleted, `Summary_Sessions` is automatically updated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Optional\n",
        "import pandas as pd\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.adapters.database.database_handler import DatabaseHandler\n",
        "from src.utils.session_id_generator import generate_session_id, find_existing_session_id\n",
        "from src.utils.summary_updater import update_summary_after_delete\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clear All Session Data\n",
        "\n",
        "**WARNING:** This will delete ALL records from all session_* tables and CSV files. This action cannot be undone!\n",
        "\n",
        "Use this when you want to start fresh with clean data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clear_all_session_data(use_dynamodb: bool = True, confirm: bool = False):\n",
        "    \"\"\"\n",
        "    Clear all session data from both DynamoDB and CSV files.\n",
        "    \n",
        "    This function:\n",
        "    1. Deletes all records from session_* tables in DynamoDB (if use_dynamodb=True)\n",
        "    2. Deletes all session_*.csv files from the data folder\n",
        "    3. Clears Summary_Sessions table/file\n",
        "    \n",
        "    Args:\n",
        "        use_dynamodb: If True, clear DynamoDB tables; if False, only clear CSV files\n",
        "        confirm: Must be True to actually perform the deletion (safety check)\n",
        "    \n",
        "    Returns:\n",
        "        True if successful, False otherwise\n",
        "    \"\"\"\n",
        "    if not confirm:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"SAFETY CHECK\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"[WARNING] This will delete ALL session data!\")\n",
        "        print(\"To proceed, call this function with confirm=True\")\n",
        "        print(\"=\" * 60)\n",
        "        return False\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"Clearing All Session Data\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Backend: {'DynamoDB' if use_dynamodb else 'CSV only'}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    session_tables = [\n",
        "        \"session_responses\",\n",
        "        \"session_gtk_responses\",\n",
        "        \"session_feedback\",\n",
        "        \"session_toxicity_rating\",\n",
        "        \"session_insights\",\n",
        "    ]\n",
        "    \n",
        "    # Clear DynamoDB tables\n",
        "    if use_dynamodb:\n",
        "        print(\"\\n[1] Clearing DynamoDB tables...\")\n",
        "        from src.adapters.database.database_handler import DatabaseHandler\n",
        "        \n",
        "        db_handler = DatabaseHandler(db_read_allowed=True, db_write_allowed=True)\n",
        "        \n",
        "        try:\n",
        "            for table_name in session_tables:\n",
        "                try:\n",
        "                    table = db_handler.backend.dynamodb.Table(table_name)\n",
        "                    \n",
        "                    # Scan and delete all items\n",
        "                    deleted_count = 0\n",
        "                    while True:\n",
        "                        response = table.scan()\n",
        "                        items = response.get(\"Items\", [])\n",
        "                        \n",
        "                        if not items:\n",
        "                            break\n",
        "                        \n",
        "                        # Delete items in batch\n",
        "                        with table.batch_writer() as batch:\n",
        "                            for item in items:\n",
        "                                # Get the primary key (usually 'id')\n",
        "                                key = {\"id\": item[\"id\"]}\n",
        "                                batch.delete_item(Key=key)\n",
        "                                deleted_count += 1\n",
        "                        \n",
        "                        # Check if there are more items\n",
        "                        if \"LastEvaluatedKey\" not in response:\n",
        "                            break\n",
        "                    \n",
        "                    print(f\"  [OK] Cleared {table_name}: {deleted_count} records deleted\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  [WARNING] Could not clear {table_name}: {e}\")\n",
        "            \n",
        "            # Clear Summary_Sessions\n",
        "            try:\n",
        "                table = db_handler.backend.dynamodb.Table(\"Summary_Sessions\")\n",
        "                response = table.scan()\n",
        "                items = response.get(\"Items\", [])\n",
        "                \n",
        "                with table.batch_writer() as batch:\n",
        "                    for item in items:\n",
        "                        key = {\"summary_id\": item[\"summary_id\"]}\n",
        "                        batch.delete_item(Key=key)\n",
        "                \n",
        "                print(f\"  [OK] Cleared Summary_Sessions: {len(items)} records deleted\")\n",
        "            except Exception as e:\n",
        "                print(f\"  [WARNING] Could not clear Summary_Sessions: {e}\")\n",
        "            \n",
        "            db_handler.close()\n",
        "            print(\"[OK] DynamoDB tables cleared\")\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Error clearing DynamoDB: {e}\")\n",
        "            db_handler.close()\n",
        "    \n",
        "    # Clear CSV files\n",
        "    print(\"\\n[2] Clearing CSV files...\")\n",
        "    from pathlib import Path\n",
        "    \n",
        "    project_root = Path().resolve().parent.parent\n",
        "    data_dir = project_root / \"data\"\n",
        "    \n",
        "    deleted_files = []\n",
        "    for table_name in session_tables:\n",
        "        csv_file = data_dir / f\"{table_name}.csv\"\n",
        "        if csv_file.exists():\n",
        "            try:\n",
        "                csv_file.unlink()\n",
        "                deleted_files.append(csv_file.name)\n",
        "                print(f\"  [OK] Deleted {csv_file.name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  [ERROR] Could not delete {csv_file.name}: {e}\")\n",
        "    \n",
        "    # Clear Summary_Sessions.csv\n",
        "    summary_file = data_dir / \"Summary_Sessions.csv\"\n",
        "    if summary_file.exists():\n",
        "        try:\n",
        "            summary_file.unlink()\n",
        "            deleted_files.append(summary_file.name)\n",
        "            print(f\"  [OK] Deleted {summary_file.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  [ERROR] Could not delete {summary_file.name}: {e}\")\n",
        "    \n",
        "    print(f\"\\n[OK] CSV files cleared: {len(deleted_files)} files deleted\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"[SUCCESS] All session data cleared!\")\n",
        "    print(\"=\" * 60)\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_summary_sessions_manual(use_dynamodb: bool = True):\n",
        "    \"\"\"\n",
        "    Manually initialize Summary_Sessions table with default values.\n",
        "    \n",
        "    This is useful when you've cleared all session data and want to\n",
        "    ensure Summary_Sessions exists with proper defaults.\n",
        "    \n",
        "    Args:\n",
        "        use_dynamodb: If True, use DynamoDB; if False, use CSV\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Initializing Summary_Sessions\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Backend: {'DynamoDB' if use_dynamodb else 'CSV'}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    from src.adapters.database.database_handler import DatabaseHandler\n",
        "    from src.utils.summary_initializer import initialize_summary_sessions\n",
        "    \n",
        "    db_handler = DatabaseHandler(db_read_allowed=use_dynamodb, db_write_allowed=use_dynamodb)\n",
        "    \n",
        "    try:\n",
        "        success = initialize_summary_sessions(db_handler)\n",
        "        if success:\n",
        "            print(\"\\n[SUCCESS] Summary_Sessions initialized successfully!\")\n",
        "        else:\n",
        "            print(\"\\n[ERROR] Failed to initialize Summary_Sessions\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERROR] Error: {e}\")\n",
        "    finally:\n",
        "        db_handler.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Summary_Sessions with default values\n",
        "# Uncomment to run\n",
        "# initialize_summary_sessions_manual(use_dynamodb=USE_DYNAMODB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear all session data\n",
        "# WARNING: This will delete ALL session records!\n",
        "# Uncomment and set confirm=True to proceed\n",
        "# clear_all_session_data(use_dynamodb=USE_DYNAMODB, confirm=False)  # Set to True to actually delete\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set `USE_DYNAMODB = True` to use DynamoDB, or `False` to use CSV files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "USE_DYNAMODB = True  # Set to False to use CSV instead\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete a Session\n",
        "\n",
        "Deletes a session record from all related tables by session_id and updates Summary_Sessions.\n",
        "\n",
        "**Note:** \n",
        "- You only need to provide the `session_id` (which is a hash of user_id and boyfriend_name)\n",
        "- The `session_id` value is stored in the `id` column in all database tables\n",
        "- You can get the `id` value from the `list_sessions()` function output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def delete_session(session_id, db_write_allowed: bool = True) -> bool:\n",
        "    \"\"\"\n",
        "    Delete a session record from all related tables based on session_id.\n",
        "    Also updates Summary_Sessions table.\n",
        "    \n",
        "    Args:\n",
        "        session_id: The session ID value (stored in the 'id' column in database tables).\n",
        "                    This is a hash of user_id and boyfriend_name.\n",
        "                    Can be int or str (will be converted to int for comparison).\n",
        "        db_write_allowed: If True, use DynamoDB; if False, use CSV\n",
        "        \n",
        "    Returns:\n",
        "        True if deletion was successful, False otherwise\n",
        "        \n",
        "    Note:\n",
        "        The session_id parameter corresponds to the 'id' column in all tables.\n",
        "        The 'id' column is stored as a number (int) in the database.\n",
        "        You can get this value from list_sessions() output.\n",
        "    \"\"\"\n",
        "    # Convert session_id to int to ensure type match with database\n",
        "    try:\n",
        "        session_id_int = int(session_id)\n",
        "    except (ValueError, TypeError):\n",
        "        print(f\"[ERROR] session_id must be a number (int or string representation of int). Got: {type(session_id)} = {session_id}\")\n",
        "        return False\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Deleting Session Record\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Session ID: {session_id_int}\")\n",
        "    print(f\"Backend: {'DynamoDB' if db_write_allowed else 'CSV'}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    db_handler = DatabaseHandler(db_write_allowed=db_write_allowed)\n",
        "    \n",
        "    try:\n",
        "        # Load the record to get its values before deleting\n",
        "        print(f\"\\n[1] Loading record with session_id {session_id_int} from session_responses...\")\n",
        "        session_responses = db_handler.load_table(\"session_responses\")\n",
        "        \n",
        "        if session_responses.empty:\n",
        "            print(\"[ERROR] session_responses table is empty\")\n",
        "            db_handler.close()\n",
        "            return False\n",
        "        \n",
        "        # Ensure 'id' column is numeric for proper comparison\n",
        "        session_responses[\"id\"] = pd.to_numeric(session_responses[\"id\"], errors='coerce')\n",
        "        \n",
        "        # Find the record by session_id (session_id is stored in the 'id' column as int)\n",
        "        record = session_responses[session_responses[\"id\"] == session_id_int]\n",
        "        \n",
        "        if record.empty:\n",
        "            print(f\"[ERROR] Record with session_id={session_id_int} not found\")\n",
        "            db_handler.close()\n",
        "            return False\n",
        "        \n",
        "        # Get values for summary update\n",
        "        row = record.iloc[0]\n",
        "        deleted_toxic_score = float(row.get(\"toxic_score\", 0))\n",
        "        deleted_filter_violations = int(row.get(\"filter_violations\", 0))\n",
        "        \n",
        "        print(f\"[OK] Found record:\")\n",
        "        print(f\"     Session ID: {session_id_int}\")\n",
        "        print(f\"     User ID: {row.get('user_id')}\")\n",
        "        print(f\"     Boyfriend Name: {row.get('boyfriend_name')}\")\n",
        "        print(f\"     Toxic Score: {deleted_toxic_score}\")\n",
        "        print(f\"     Filter Violations: {deleted_filter_violations}\")\n",
        "        \n",
        "        # Delete the record from all related tables\n",
        "        print(f\"\\n[2] Deleting records with session_id {session_id_int} from all tables...\")\n",
        "        tables_to_delete = [\n",
        "            \"session_responses\",\n",
        "            \"session_gtk_responses\",\n",
        "            \"session_feedback\",\n",
        "            \"session_toxicity_rating\",\n",
        "            \"session_insights\",\n",
        "        ]\n",
        "        \n",
        "        deleted_count = 0\n",
        "        for table_name in tables_to_delete:\n",
        "            try:\n",
        "                # Delete record using session_id_int (which is stored in the 'id' column as int)\n",
        "                if db_handler.delete_record(table_name, session_id_int, id_column=\"id\"):\n",
        "                    deleted_count += 1\n",
        "                    print(f\"[OK] Deleted from {table_name}\")\n",
        "                else:\n",
        "                    print(f\"[INFO] No record found in {table_name} (may not exist for this session)\")\n",
        "            except Exception as e:\n",
        "                print(f\"[WARNING] Could not delete from {table_name}: {e}\")\n",
        "        \n",
        "        if deleted_count == 0:\n",
        "            print(\"[ERROR] Failed to delete any records\")\n",
        "            db_handler.close()\n",
        "            return False\n",
        "        \n",
        "        # Update Summary_Sessions\n",
        "        print(f\"\\n[3] Updating Summary_Sessions...\")\n",
        "        update_success = update_summary_after_delete(\n",
        "            db_handler=db_handler,\n",
        "            deleted_toxic_score=deleted_toxic_score,\n",
        "            deleted_filter_violations=deleted_filter_violations,\n",
        "        )\n",
        "        \n",
        "        if not update_success:\n",
        "            print(\"[WARNING] Record deleted but Summary_Sessions update failed\")\n",
        "        \n",
        "        db_handler.close()\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"[SUCCESS] Session record deleted and Summary_Sessions updated!\")\n",
        "        print(\"=\" * 60)\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERROR] Error deleting session: {e}\")\n",
        "        import traceback\n",
        "        print(f\"[ERROR] Traceback: {traceback.format_exc()}\")\n",
        "        db_handler.close()\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Deleting Session Record\n",
            "============================================================\n",
            "Session ID: 12\n",
            "Backend: DynamoDB\n",
            "============================================================\n",
            "[INFO] Running locally, looking for credentials in file\n",
            "[OK] AWS DynamoDB connection established\n",
            "\n",
            "[1] Loading record with session_id 12 from session_responses...\n",
            "[OK] Found record:\n",
            "     Session ID: 12\n",
            "     User ID: 60b7e7a2-0c76-4593-a6e6-e45fef8cf874\n",
            "     Boyfriend Name: Test1\n",
            "     Toxic Score: 0.26752\n",
            "     Filter Violations: 0\n",
            "\n",
            "[2] Deleting records with session_id 12 from all tables...\n",
            "[OK] Deleted record with id=12 from session_responses\n",
            "[OK] Deleted from session_responses\n",
            "[OK] Deleted record with id=12 from session_gtk_responses\n",
            "[OK] Deleted from session_gtk_responses\n",
            "[OK] Deleted record with id=12 from session_feedback\n",
            "[OK] Deleted from session_feedback\n",
            "[OK] Deleted record with id=12 from session_toxicity_rating\n",
            "[OK] Deleted from session_toxicity_rating\n",
            "[WARNING] No record found with id=12 in session_insights\n",
            "[INFO] No record found in session_insights (may not exist for this session)\n",
            "\n",
            "[3] Updating Summary_Sessions...\n",
            "[ERROR] Error updating DynamoDB record: Float types are not supported. Use Decimal types instead.\n",
            "[OK] Updated Summary_Sessions after delete. New count_guys: 11, avg_toxic_score: 0.2551\n",
            "[CLOSED] AWS DynamoDB connection closed\n",
            "\n",
            "============================================================\n",
            "[SUCCESS] Session record deleted and Summary_Sessions updated!\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example: Delete a session\n",
        "# Uncomment and modify the session_id below to delete a session\n",
        "# Note: session_id is the value stored in the 'id' column in the database tables\n",
        "# You can get this value from the list_sessions() function output (shown as \"Session ID\")\n",
        "\n",
        "# delete_session(\n",
        "#     session_id=\"12\",  # This is the 'id' column value from the table\n",
        "#     db_write_allowed=USE_DYNAMODB\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update a Record\n",
        "\n",
        "Updates a record in a specific table by session_id.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_session_record(\n",
        "    table_name: str,\n",
        "    session_id: int,\n",
        "    update_data: Dict[str, Any],\n",
        "    db_write_allowed: bool = True\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Update a record in a specific table by session_id.\n",
        "    \n",
        "    Args:\n",
        "        table_name: Name of the table to update\n",
        "        session_id: Session ID of the record to update\n",
        "        update_data: Dictionary of fields to update\n",
        "        db_write_allowed: If True, use DynamoDB; if False, use CSV\n",
        "        \n",
        "    Returns:\n",
        "        True if update was successful, False otherwise\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Updating Session Record\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Table: {table_name}\")\n",
        "    print(f\"Session ID: {session_id}\")\n",
        "    print(f\"Backend: {'DynamoDB' if db_write_allowed else 'CSV'}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    db_handler = DatabaseHandler(db_write_allowed=db_write_allowed)\n",
        "    \n",
        "    try:\n",
        "        # Check if record exists\n",
        "        print(f\"\\n[1] Checking if record exists in {table_name}...\")\n",
        "        table_data = db_handler.load_table(table_name)\n",
        "        \n",
        "        if table_data.empty:\n",
        "            print(f\"[ERROR] Table '{table_name}' is empty\")\n",
        "            db_handler.close()\n",
        "            return False\n",
        "        \n",
        "        # Find the record\n",
        "        record = table_data[table_data[\"id\"] == session_id]\n",
        "        \n",
        "        if record.empty:\n",
        "            print(f\"[ERROR] Record with session_id={session_id} not found in {table_name}\")\n",
        "            db_handler.close()\n",
        "            return False\n",
        "        \n",
        "        print(f\"[OK] Found record in {table_name}\")\n",
        "        print(f\"     Current values: {dict(record.iloc[0].head(5))}...\")\n",
        "        \n",
        "        # Update the record\n",
        "        print(f\"\\n[2] Updating record...\")\n",
        "        print(f\"     Fields to update: {list(update_data.keys())}\")\n",
        "        \n",
        "        db_handler.update_record(\n",
        "            table_name=table_name,\n",
        "            key_dict={\"id\": session_id},\n",
        "            update_dict=update_data\n",
        "        )\n",
        "        \n",
        "        print(f\"[OK] Record updated successfully!\")\n",
        "        \n",
        "        db_handler.close()\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"[SUCCESS] Record updated!\")\n",
        "        print(\"=\" * 60)\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERROR] Error updating record: {e}\")\n",
        "        import traceback\n",
        "        print(f\"[ERROR] Traceback: {traceback.format_exc()}\")\n",
        "        db_handler.close()\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Update a record\n",
        "# Uncomment and modify the values below to update a record\n",
        "\n",
        "# update_session_record(\n",
        "#     table_name=\"session_responses\",\n",
        "#     session_id=123456789,\n",
        "#     update_data={\n",
        "#         \"toxic_score\": 0.75,\n",
        "#         \"filter_violations\": 2\n",
        "#     },\n",
        "#     db_write_allowed=USE_DYNAMODB\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List Sessions\n",
        "\n",
        "Lists all sessions or sessions for a specific user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_sessions(user_id: Optional[str] = None, db_write_allowed: bool = True) -> None:\n",
        "    \"\"\"\n",
        "    List all sessions or sessions for a specific user.\n",
        "    \n",
        "    Args:\n",
        "        user_id: Optional user ID to filter by. If None, lists all sessions.\n",
        "        db_write_allowed: If True, use DynamoDB; if False, use CSV\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Listing Sessions\")\n",
        "    print(\"=\" * 60)\n",
        "    if user_id:\n",
        "        print(f\"Filter: user_id = {user_id}\")\n",
        "    else:\n",
        "        print(\"Filter: All sessions\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    db_handler = DatabaseHandler(db_write_allowed=db_write_allowed)\n",
        "    \n",
        "    try:\n",
        "        session_responses = db_handler.load_table(\"session_responses\")\n",
        "        \n",
        "        if session_responses.empty:\n",
        "            print(\"[INFO] No sessions found\")\n",
        "            db_handler.close()\n",
        "            return\n",
        "        \n",
        "        # Filter by user_id if provided\n",
        "        if user_id:\n",
        "            filtered = session_responses[session_responses[\"user_id\"] == user_id]\n",
        "        else:\n",
        "            filtered = session_responses\n",
        "        \n",
        "        if filtered.empty:\n",
        "            print(f\"[INFO] No sessions found for user_id={user_id}\")\n",
        "            db_handler.close()\n",
        "            return\n",
        "        \n",
        "        print(f\"\\n[OK] Found {len(filtered)} session(s):\\n\")\n",
        "        \n",
        "        # Display sessions\n",
        "        for idx, (_, row) in enumerate(filtered.iterrows(), 1):\n",
        "            print(f\"Session {idx}:\")\n",
        "            print(f\"  Session ID: {row.get('id')}\")\n",
        "            print(f\"  User ID: {row.get('user_id')}\")\n",
        "            print(f\"  Name: {row.get('name')}\")\n",
        "            print(f\"  Boyfriend Name: {row.get('boyfriend_name')}\")\n",
        "            print(f\"  Toxic Score: {row.get('toxic_score')}\")\n",
        "            print(f\"  Filter Violations: {row.get('filter_violations')}\")\n",
        "            print(f\"  Language: {row.get('language')}\")\n",
        "            print(f\"  Session Start: {row.get('session_start_time')}\")\n",
        "            print()\n",
        "        \n",
        "        db_handler.close()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERROR] Error listing sessions: {e}\")\n",
        "        import traceback\n",
        "        print(f\"[ERROR] Traceback: {traceback.format_exc()}\")\n",
        "        db_handler.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: List all sessions\n",
        "list_sessions(db_write_allowed=USE_DYNAMODB)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reassign Session IDs and Recalculate Summary_Sessions\n",
        "\n",
        "This section:\n",
        "1. Groups records by (user_id, test_date, boyfriend_name) combination\n",
        "2. Assigns the same session_id to all records with matching combinations across all CSV files\n",
        "3. Recalculates Summary_Sessions based on the updated data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from decimal import Decimal\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.utils.session_id_generator import generate_session_id\n",
        "from src.utils.constants import DATE_FORMAT, CSV_SEPARATOR\n",
        "\n",
        "# Configuration\n",
        "DATA_DIR = project_root / \"data\"\n",
        "CSV_FILES = {\n",
        "    \"session_responses\": \"session_responses.csv\",\n",
        "    \"session_gtk_responses\": \"session_gtk_responses.csv\",\n",
        "    \"session_feedback\": \"session_feedback.csv\",\n",
        "    \"session_toxicity_rating\": \"session_toxicity_rating.csv\",\n",
        "    \"session_insights\": \"session_insights.csv\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_session_id_with_date(user_id: str, boyfriend_name: str, test_date: str) -> int:\n",
        "    \"\"\"\n",
        "    Generate a unique, deterministic session_id based on user_id, boyfriend_name, and test_date.\n",
        "    \n",
        "    Args:\n",
        "        user_id: Unique identifier for the user\n",
        "        boyfriend_name: Name of the boyfriend being rated\n",
        "        test_date: Test date (session date)\n",
        "        \n",
        "    Returns:\n",
        "        A positive integer session_id\n",
        "    \"\"\"\n",
        "    # Normalize inputs\n",
        "    user_id_norm = str(user_id).lower().strip()\n",
        "    bf_name_norm = str(boyfriend_name).lower().strip()\n",
        "    test_date_norm = str(test_date).strip()\n",
        "    \n",
        "    # Create a deterministic string from all three components\n",
        "    combined = f\"{user_id_norm}_{bf_name_norm}_{test_date_norm}\"\n",
        "    \n",
        "    # Generate hash using SHA256\n",
        "    hash_obj = hashlib.sha256(combined.encode('utf-8'))\n",
        "    hash_hex = hash_obj.hexdigest()\n",
        "    \n",
        "    # Convert first 8 characters of hash to integer\n",
        "    session_id = int(hash_hex[:8], 16) % (2**31 - 1)\n",
        "    \n",
        "    # Ensure it's positive and at least 1\n",
        "    if session_id == 0:\n",
        "        session_id = 1\n",
        "    \n",
        "    return session_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_test_date_column(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Determine which column contains the test date.\"\"\"\n",
        "    # Check common column names for test date (in priority order)\n",
        "    # Prefer session_start_time as it's more consistent across tables\n",
        "    date_columns = ['session_start_time', 'test_date', 'timestamp']\n",
        "    for col in date_columns:\n",
        "        if col in df.columns:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def normalize_date(date_value):\n",
        "    \"\"\"Normalize date to string format using consistent DATE_FORMAT.\"\"\"\n",
        "    if pd.isna(date_value):\n",
        "        return None\n",
        "    # Convert to string and strip\n",
        "    date_str = str(date_value).strip()\n",
        "    # If it's a datetime object, format it consistently\n",
        "    try:\n",
        "        if isinstance(date_value, pd.Timestamp):\n",
        "            return date_value.strftime(DATE_FORMAT)\n",
        "        # Try parsing if it's a string and reformat\n",
        "        parsed_date = pd.to_datetime(date_str)\n",
        "        return parsed_date.strftime(DATE_FORMAT)\n",
        "    except:\n",
        "        return date_str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_csv_separator(file_path):\n",
        "    \"\"\"Detect CSV separator by reading first line.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            first_line = f.readline()\n",
        "            # Count semicolons and commas\n",
        "            semicolon_count = first_line.count(';')\n",
        "            comma_count = first_line.count(',')\n",
        "            # Use semicolon if it appears, otherwise comma\n",
        "            if semicolon_count > 0:\n",
        "                return ';'\n",
        "            elif comma_count > 0:\n",
        "                return ','\n",
        "            else:\n",
        "                return CSV_SEPARATOR  # Default\n",
        "    except:\n",
        "        return CSV_SEPARATOR  # Default fallback\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    \"\"\"Load all CSV files and prepare them for session ID assignment.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Loading CSV Files\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    data = {}\n",
        "    \n",
        "    for table_name, filename in CSV_FILES.items():\n",
        "        file_path = DATA_DIR / filename\n",
        "        if not file_path.exists():\n",
        "            print(f\"[WARNING] File not found: {filename}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            # Detect separator for each file\n",
        "            separator = detect_csv_separator(file_path)\n",
        "            df = pd.read_csv(file_path, sep=separator)\n",
        "            print(f\"[OK] Loaded {filename}: {len(df)} records (separator: '{separator}')\")\n",
        "            data[table_name] = df\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed to load {filename}: {e}\")\n",
        "    \n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_session_mapping(data: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Create a mapping of (user_id, test_date, boyfriend_name) -> session_id.\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary mapping (user_id, test_date, boyfriend_name) tuples to session_id\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Creating Session ID Mapping\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    session_mapping = {}\n",
        "    \n",
        "    # Process each table to extract unique combinations\n",
        "    for table_name, df in data.items():\n",
        "        if df.empty:\n",
        "            continue\n",
        "        \n",
        "        # Get required columns - check with case-insensitive matching\n",
        "        df_columns_lower = [col.lower().strip() for col in df.columns]\n",
        "        user_id_col = None\n",
        "        boyfriend_name_col = None\n",
        "        \n",
        "        for col in df.columns:\n",
        "            col_lower = col.lower().strip()\n",
        "            if col_lower == 'user_id':\n",
        "                user_id_col = col\n",
        "            elif col_lower == 'boyfriend_name':\n",
        "                boyfriend_name_col = col\n",
        "        \n",
        "        if not user_id_col or not boyfriend_name_col:\n",
        "            print(f\"[WARNING] {table_name} missing required columns. Available columns: {list(df.columns[:10])}\")\n",
        "            continue\n",
        "        \n",
        "        # Get test_date column\n",
        "        date_col = get_test_date_column(df)\n",
        "        if not date_col:\n",
        "            print(f\"[WARNING] {table_name} has no date column (test_date, session_start_time, or timestamp)\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nProcessing {table_name}...\")\n",
        "        \n",
        "        # Extract unique combinations\n",
        "        for idx, row in df.iterrows():\n",
        "            user_id = str(row[user_id_col]).strip()\n",
        "            boyfriend_name = str(row[boyfriend_name_col]).strip()\n",
        "            test_date = normalize_date(row[date_col])\n",
        "            \n",
        "            if not user_id or not boyfriend_name or not test_date:\n",
        "                print(f\"[WARNING] Row {idx} in {table_name} has missing values, skipping\")\n",
        "                continue\n",
        "            \n",
        "            key = (user_id, test_date, boyfriend_name)\n",
        "            \n",
        "            # Generate session_id if not already in mapping\n",
        "            if key not in session_mapping:\n",
        "                session_id = generate_session_id_with_date(user_id, boyfriend_name, test_date)\n",
        "                session_mapping[key] = session_id\n",
        "                print(f\"  Created mapping: ({user_id[:8]}..., {test_date[:10]}..., {boyfriend_name}) -> {session_id}\")\n",
        "    \n",
        "    print(f\"\\n[OK] Created {len(session_mapping)} unique session mappings\")\n",
        "    return session_mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_session_ids(data: dict, session_mapping: dict):\n",
        "    \"\"\"Update session IDs in all dataframes based on the mapping.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Updating Session IDs\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    updated_data = {}\n",
        "    \n",
        "    for table_name, df in data.items():\n",
        "        if df.empty:\n",
        "            updated_data[table_name] = df\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nUpdating {table_name}...\")\n",
        "        df = df.copy()\n",
        "        \n",
        "        # Get required columns - check with case-insensitive matching\n",
        "        user_id_col = None\n",
        "        boyfriend_name_col = None\n",
        "        \n",
        "        for col in df.columns:\n",
        "            col_lower = col.lower().strip()\n",
        "            if col_lower == 'user_id':\n",
        "                user_id_col = col\n",
        "            elif col_lower == 'boyfriend_name':\n",
        "                boyfriend_name_col = col\n",
        "        \n",
        "        if not user_id_col or not boyfriend_name_col:\n",
        "            print(f\"[WARNING] {table_name} missing required columns, skipping. Available: {list(df.columns[:10])}\")\n",
        "            updated_data[table_name] = df\n",
        "            continue\n",
        "        \n",
        "        # Get test_date column\n",
        "        date_col = get_test_date_column(df)\n",
        "        if not date_col:\n",
        "            print(f\"[WARNING] {table_name} has no date column, skipping\")\n",
        "            updated_data[table_name] = df\n",
        "            continue\n",
        "        \n",
        "        # Update IDs\n",
        "        updated_count = 0\n",
        "        skipped_count = 0\n",
        "        \n",
        "        for idx, row in df.iterrows():\n",
        "            user_id = str(row[user_id_col]).strip()\n",
        "            boyfriend_name = str(row[boyfriend_name_col]).strip()\n",
        "            test_date = normalize_date(row[date_col])\n",
        "            \n",
        "            if not user_id or not boyfriend_name or not test_date:\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "            \n",
        "            key = (user_id, test_date, boyfriend_name)\n",
        "            \n",
        "            if key in session_mapping:\n",
        "                new_id = session_mapping[key]\n",
        "                old_id = row.get('id')\n",
        "                df.at[idx, 'id'] = new_id\n",
        "                if old_id != new_id:\n",
        "                    updated_count += 1\n",
        "            else:\n",
        "                skipped_count += 1\n",
        "        \n",
        "        print(f\"  Updated: {updated_count} records\")\n",
        "        if skipped_count > 0:\n",
        "            print(f\"  Skipped: {skipped_count} records (missing values)\")\n",
        "        \n",
        "        updated_data[table_name] = df\n",
        "    \n",
        "    return updated_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_updated_csvs(updated_data: dict, backup: bool = True):\n",
        "    \"\"\"Save updated dataframes to CSV files.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Saving Updated CSV Files\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    if backup:\n",
        "        # Create backup directory\n",
        "        backup_dir = DATA_DIR / \"backup\"\n",
        "        backup_dir.mkdir(exist_ok=True)\n",
        "        print(f\"[INFO] Backups will be saved to: {backup_dir}\")\n",
        "    \n",
        "    for table_name, df in updated_data.items():\n",
        "        if table_name not in CSV_FILES:\n",
        "            continue\n",
        "        \n",
        "        filename = CSV_FILES[table_name]\n",
        "        file_path = DATA_DIR / filename\n",
        "        \n",
        "        # Backup original if requested\n",
        "        if backup and file_path.exists():\n",
        "            backup_path = backup_dir / f\"{filename}.backup\"\n",
        "            import shutil\n",
        "            shutil.copy2(file_path, backup_path)\n",
        "            print(f\"[OK] Backed up {filename}\")\n",
        "        \n",
        "        # Save updated file\n",
        "        try:\n",
        "            df.to_csv(file_path, index=False)\n",
        "            print(f\"[OK] Saved {filename} ({len(df)} records)\")\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed to save {filename}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recalculate_summary_sessions(data: dict):\n",
        "    \"\"\"Recalculate Summary_Sessions table from session_responses.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Recalculating Summary_Sessions\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    if \"session_responses\" not in data:\n",
        "        print(\"[ERROR] session_responses not found in data\")\n",
        "        return None\n",
        "    \n",
        "    df = data[\"session_responses\"]\n",
        "    \n",
        "    if df.empty:\n",
        "        print(\"[WARNING] session_responses is empty\")\n",
        "        return None\n",
        "    \n",
        "    # Required columns\n",
        "    required_cols = ['toxic_score', 'filter_violations']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"[ERROR] session_responses missing required columns: {required_cols}\")\n",
        "        return None\n",
        "    \n",
        "    # Convert to numeric\n",
        "    df['toxic_score'] = pd.to_numeric(df['toxic_score'], errors='coerce')\n",
        "    df['filter_violations'] = pd.to_numeric(df['filter_violations'], errors='coerce')\n",
        "    \n",
        "    # Remove rows with NaN values\n",
        "    df_clean = df.dropna(subset=['toxic_score', 'filter_violations'])\n",
        "    \n",
        "    if df_clean.empty:\n",
        "        print(\"[WARNING] No valid records after cleaning\")\n",
        "        return None\n",
        "    \n",
        "    # Calculate statistics\n",
        "    sum_toxic_score = float(df_clean['toxic_score'].sum())\n",
        "    max_toxic_score = float(df_clean['toxic_score'].max())\n",
        "    min_toxic_score = float(df_clean['toxic_score'].min())\n",
        "    avg_toxic_score = float(df_clean['toxic_score'].mean())\n",
        "    \n",
        "    sum_filter_violations = int(df_clean['filter_violations'].sum())\n",
        "    avg_filter_violations = float(df_clean['filter_violations'].mean())\n",
        "    \n",
        "    # Count unique sessions (unique id values)\n",
        "    count_guys = df_clean['id'].nunique()\n",
        "    \n",
        "    # Get max IDs from each table (for backward compatibility, but set to 0 as per code)\n",
        "    max_id_session_responses = 0\n",
        "    max_id_gtk_responses = 0\n",
        "    max_id_feedback = 0\n",
        "    max_id_session_toxicity_rating = 0\n",
        "    \n",
        "    last_update_date = datetime.now().strftime(DATE_FORMAT)\n",
        "    \n",
        "    summary_data = {\n",
        "        'summary_id': 1,\n",
        "        'sum_toxic_score': sum_toxic_score,\n",
        "        'max_toxic_score': max_toxic_score,\n",
        "        'min_toxic_score': min_toxic_score,\n",
        "        'avg_toxic_score': avg_toxic_score,\n",
        "        'sum_filter_violations': sum_filter_violations,\n",
        "        'avg_filter_violations': avg_filter_violations,\n",
        "        'count_guys': count_guys,\n",
        "        'max_id_session_responses': max_id_session_responses,\n",
        "        'max_id_gtk_responses': max_id_gtk_responses,\n",
        "        'max_id_feedback': max_id_feedback,\n",
        "        'max_id_session_toxicity_rating': max_id_session_toxicity_rating,\n",
        "        'last_update_date': last_update_date,\n",
        "    }\n",
        "    \n",
        "    print(f\"[OK] Calculated Summary_Sessions:\")\n",
        "    print(f\"  count_guys: {count_guys}\")\n",
        "    print(f\"  avg_toxic_score: {avg_toxic_score:.6f}\")\n",
        "    print(f\"  sum_toxic_score: {sum_toxic_score:.6f}\")\n",
        "    print(f\"  sum_filter_violations: {sum_filter_violations}\")\n",
        "    \n",
        "    return summary_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_summary_sessions(summary_data: dict):\n",
        "    \"\"\"Save Summary_Sessions to CSV.\"\"\"\n",
        "    if summary_data is None:\n",
        "        return\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Saving Summary_Sessions\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    file_path = DATA_DIR / \"Summary_Sessions.csv\"\n",
        "    \n",
        "    # Backup if exists\n",
        "    if file_path.exists():\n",
        "        backup_dir = DATA_DIR / \"backup\"\n",
        "        backup_dir.mkdir(exist_ok=True)\n",
        "        import shutil\n",
        "        backup_path = backup_dir / \"Summary_Sessions.csv.backup\"\n",
        "        shutil.copy2(file_path, backup_path)\n",
        "        print(f\"[OK] Backed up Summary_Sessions.csv\")\n",
        "    \n",
        "    # Create DataFrame and save with consistent separator\n",
        "    df = pd.DataFrame([summary_data])\n",
        "    df.to_csv(file_path, sep=CSV_SEPARATOR, index=False)\n",
        "    print(f\"[OK] Saved Summary_Sessions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_changes_summary(data: dict, updated_data: dict, session_mapping: dict):\n",
        "    \"\"\"Show a summary of changes before saving.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Changes Summary\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    print(f\"\\nTotal unique sessions: {len(session_mapping)}\")\n",
        "    \n",
        "    print(\"\\nSession ID changes per table:\")\n",
        "    for table_name in CSV_FILES.keys():\n",
        "        if table_name not in data or table_name not in updated_data:\n",
        "            continue\n",
        "        \n",
        "        old_df = data[table_name]\n",
        "        new_df = updated_data[table_name]\n",
        "        \n",
        "        if old_df.empty or new_df.empty:\n",
        "            continue\n",
        "        \n",
        "        # Count changed IDs\n",
        "        if 'id' in old_df.columns and 'id' in new_df.columns:\n",
        "            changes = (old_df['id'] != new_df['id']).sum()\n",
        "            total = len(old_df)\n",
        "            print(f\"  {table_name}: {changes}/{total} records updated\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "def reassign_session_ids_and_recalculate(dry_run: bool = False):\n",
        "    \"\"\"\n",
        "    Main function to reassign session IDs and recalculate Summary_Sessions.\n",
        "    \n",
        "    Args:\n",
        "        dry_run: If True, only show what would be changed without saving files\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Reassign Session IDs and Recalculate Summary_Sessions\")\n",
        "    if dry_run:\n",
        "        print(\"DRY RUN MODE - No files will be modified\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Step 1: Load data\n",
        "    data = load_and_prepare_data()\n",
        "    \n",
        "    if not data:\n",
        "        print(\"[ERROR] No data loaded\")\n",
        "        return\n",
        "    \n",
        "    # Step 2: Create session mapping\n",
        "    session_mapping = create_session_mapping(data)\n",
        "    \n",
        "    if not session_mapping:\n",
        "        print(\"[ERROR] No session mappings created\")\n",
        "        return\n",
        "    \n",
        "    # Step 3: Update session IDs\n",
        "    updated_data = update_session_ids(data, session_mapping)\n",
        "    \n",
        "    # Step 4: Show summary\n",
        "    show_changes_summary(data, updated_data, session_mapping)\n",
        "    \n",
        "    if dry_run:\n",
        "        print(\"\\n[INFO] Dry run completed. No files were modified.\")\n",
        "        print(\"Set dry_run=False to apply changes.\")\n",
        "        return\n",
        "    \n",
        "    # Step 5: Save updated CSVs\n",
        "    save_updated_csvs(updated_data, backup=True)\n",
        "    \n",
        "    # Step 6: Recalculate Summary_Sessions\n",
        "    summary_data = recalculate_summary_sessions(updated_data)\n",
        "    \n",
        "    # Step 7: Save Summary_Sessions\n",
        "    save_summary_sessions(summary_data)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"[SUCCESS] All operations completed!\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Reassign Session IDs and Recalculate Summary_Sessions\n",
            "============================================================\n",
            "============================================================\n",
            "Loading CSV Files\n",
            "============================================================\n",
            "[OK] Loaded session_responses.csv: 12 records (separator: ',')\n",
            "[OK] Loaded session_gtk_responses.csv: 12 records (separator: ',')\n",
            "[OK] Loaded session_feedback.csv: 10 records (separator: ',')\n",
            "[OK] Loaded session_toxicity_rating.csv: 12 records (separator: ',')\n",
            "[OK] Loaded session_insights.csv: 7 records (separator: ',')\n",
            "\n",
            "============================================================\n",
            "Creating Session ID Mapping\n",
            "============================================================\n",
            "\n",
            "Processing session_responses...\n",
            "  Created mapping: (3013b931..., 2025-03-28..., Berke) -> 1231198605\n",
            "  Created mapping: (3013b931..., 2025-03-28..., Cemberk) -> 694732827\n",
            "  Created mapping: (be4b46dc..., 2025-03-29..., Aaron) -> 700972892\n",
            "  Created mapping: (177bc767..., 2025-03-26..., toksik kaan) -> 1342029424\n",
            "  Created mapping: (177bc767..., 2025-03-26..., ozan) -> 1315277317\n",
            "  Created mapping: (1477a67f..., 2025-03-27..., bok) -> 1353492132\n",
            "  Created mapping: (44ed9413..., 2025-10-21..., sergei) -> 1022067251\n",
            "  Created mapping: (0ee1c646..., 2025-03-27..., lucas) -> 107188685\n",
            "  Created mapping: (177bc767..., 2025-03-26..., sergei) -> 293672453\n",
            "  Created mapping: (4e7f5f7e..., 2025-03-27..., Adil) -> 1054185429\n",
            "  Created mapping: (be4b46dc..., 2025-03-29..., \"Gio \") -> 827537782\n",
            "\n",
            "Processing session_gtk_responses...\n",
            "\n",
            "Processing session_feedback...\n",
            "\n",
            "Processing session_toxicity_rating...\n",
            "\n",
            "Processing session_insights...\n",
            "[WARNING] Row 0 in session_insights has missing values, skipping\n",
            "[WARNING] Row 1 in session_insights has missing values, skipping\n",
            "[WARNING] Row 2 in session_insights has missing values, skipping\n",
            "[WARNING] Row 3 in session_insights has missing values, skipping\n",
            "[WARNING] Row 4 in session_insights has missing values, skipping\n",
            "[WARNING] Row 5 in session_insights has missing values, skipping\n",
            "[WARNING] Row 6 in session_insights has missing values, skipping\n",
            "\n",
            "[OK] Created 11 unique session mappings\n",
            "\n",
            "============================================================\n",
            "Updating Session IDs\n",
            "============================================================\n",
            "\n",
            "Updating session_responses...\n",
            "  Updated: 12 records\n",
            "\n",
            "Updating session_gtk_responses...\n",
            "  Updated: 12 records\n",
            "\n",
            "Updating session_feedback...\n",
            "  Updated: 10 records\n",
            "\n",
            "Updating session_toxicity_rating...\n",
            "  Updated: 12 records\n",
            "\n",
            "Updating session_insights...\n",
            "  Updated: 0 records\n",
            "  Skipped: 7 records (missing values)\n",
            "\n",
            "============================================================\n",
            "Changes Summary\n",
            "============================================================\n",
            "\n",
            "Total unique sessions: 11\n",
            "\n",
            "Session ID changes per table:\n",
            "  session_responses: 12/12 records updated\n",
            "  session_gtk_responses: 12/12 records updated\n",
            "  session_feedback: 10/10 records updated\n",
            "  session_toxicity_rating: 12/12 records updated\n",
            "  session_insights: 7/7 records updated\n",
            "\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Saving Updated CSV Files\n",
            "============================================================\n",
            "[INFO] Backups will be saved to: C:\\Users\\Pelin\\Documents\\Projects\\runawayguys\\data\\backup\n",
            "[OK] Backed up session_responses.csv\n",
            "[OK] Saved session_responses.csv (12 records)\n",
            "[OK] Backed up session_gtk_responses.csv\n",
            "[OK] Saved session_gtk_responses.csv (12 records)\n",
            "[OK] Backed up session_feedback.csv\n",
            "[OK] Saved session_feedback.csv (10 records)\n",
            "[OK] Backed up session_toxicity_rating.csv\n",
            "[OK] Saved session_toxicity_rating.csv (12 records)\n",
            "[OK] Backed up session_insights.csv\n",
            "[OK] Saved session_insights.csv (7 records)\n",
            "\n",
            "============================================================\n",
            "Recalculating Summary_Sessions\n",
            "============================================================\n",
            "[OK] Calculated Summary_Sessions:\n",
            "  count_guys: 11\n",
            "  avg_toxic_score: 0.260691\n",
            "  sum_toxic_score: 3.128290\n",
            "  sum_filter_violations: 42\n",
            "\n",
            "============================================================\n",
            "Saving Summary_Sessions\n",
            "============================================================\n",
            "[OK] Backed up Summary_Sessions.csv\n",
            "[OK] Saved Summary_Sessions.csv\n",
            "\n",
            "============================================================\n",
            "[SUCCESS] All operations completed!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Run the reassignment process\n",
        "# First run with dry_run=True to preview changes, then set to False to apply\n",
        "reassign_session_ids_and_recalculate(dry_run=False)  # Preview changes\n",
        "# reassign_session_ids_and_recalculate(dry_run=False)  # Apply changes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: List sessions for a specific user\n",
        "# Uncomment and modify the user_id below\n",
        "\n",
        "# list_sessions(user_id=\"your_user_id_here\", db_write_allowed=USE_DYNAMODB)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (runawayguys)",
      "language": "python",
      "name": "runawayguys"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
